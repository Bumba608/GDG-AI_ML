{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Exploratory Data Analysis (EDA)**# \n\n**This notebook provides an exploratory data analysis of the developer role classification dataset. The goal is to understand the dataset's structure, identify potential issues, visualize feature distributions, and gain insights that can inform preprocessing and modeling decisions.**","metadata":{}},{"cell_type":"markdown","source":"# **Load Data**","metadata":{}},{"cell_type":"code","source":"import padas as pd\nfile_path = '/content/final_dataset.csv'\ntry:\n    df = pd.read_csv(file_path)\n    print(\"Dataset loaded successfully.\")\n    print(f\"Dataset shape: {df.shape}\")\nexcept FileNotFoundError:\n    print(f\"Error: Dataset not found at {file_path}\")\n    df = None # Set df to None if loading fails","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"if df is not None:\n    print(\"\\nFirst 5 rows of the dataset:\")\n    display(df.head())\n\n    print(\"\\nColumn information:\")\n    df.info()\n\n    print(\"\\nMissing values per column:\")\n    print(df.isnull().sum())\nelse:\n    print(\"Data not loaded, skipping overview.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Target Variable Distribution**\n\n**Let's examine the distribution of the target variable, 'role'. This is important to understand if there is any class imbalance.**","metadata":{}},{"cell_type":"code","source":"if df is not None:\n    plt.figure(figsize=(8, 6))\n    sns.countplot(x='role', data=df, palette='viridis')\n    plt.title('Distribution of Developer Roles')\n    plt.xlabel('Developer Role')\n    plt.ylabel('Count')\n    plt.show()\n\n    print(\"\\nValue counts for 'role':\")\n    print(df['role'].value_counts())\n    print(\"\\nPercentage distribution of 'role':\")\n    print(df['role'].value_counts(normalize=True).round(3))\nelse:\n     print(\"Data not loaded, skipping target distribution analysis.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Explore Numerical Features**\n\n**Let's analyze the distribution of numerical features like numfileschanged, linesadded, linesdeleted, and numcommentsadded. We can use histograms to visualize their distributions**","metadata":{}},{"cell_type":"code","source":"if df is not None:\n    numerical_features = ['numfileschanged', 'linesadded', 'linesdeleted', 'numcommentsadded']\n\n    plt.figure(figsize=(15, 10))\n    for i, feature in enumerate(numerical_features):\n        plt.subplot(2, 2, i + 1)\n        sns.histplot(df[feature], kde=True, bins=30, color='skyblue')\n        plt.title(f'Distribution of {feature}')\n        plt.xlabel(feature)\n        plt.ylabel('Frequency')\n    plt.tight_layout()\n    plt.show()\nelse:\n    print(\"Data not loaded, skipping numerical feature analysis.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Explore Categorical Features**\n\n**Let's look at the distribution of the committype.**","metadata":{}},{"cell_type":"code","source":"if df is not None:\n    plt.figure(figsize=(8, 6))\n    sns.countplot(x='committype', data=df, palette='viridis')\n    plt.title('Distribution of Commit Types')\n    plt.xlabel('Commit Type')\n    plt.ylabel('Count')\n    plt.show()\n\n    print(\"\\nValue counts for 'committype':\")\n    print(df['committype'].value_counts())\n    print(\"\\nPercentage distribution of 'committype':\")\n    print(df['committype'].value_counts(normalize=True).round(3))\nelse:\n     print(\"Data not loaded, skipping categorical feature analysis.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Explore File Extensions**\n\nThe fileextensions column is a string representation of a list. We need to process it to understand the distribution of file types.","metadata":{}},{"cell_type":"code","source":"if df is not None:\n    # Function to safely evaluate the string list and flatten it\n    def flatten_extensions(ext_str):\n        try:\n            # Safely evaluate the string representation of the list\n            extensions_list = ast.literal_eval(ext_str)\n            # Ensure it's a list of strings, filter out non-string or empty values\n            valid_extensions = [ext.strip().replace('.', '') for ext in extensions_list if isinstance(ext, str) and ext.strip()]\n            return valid_extensions\n        except (ValueError, SyntaxError):\n            return [] # Return empty list if evaluation fails or invalid format\n\n    # Apply the function and explode the list of extensions into separate rows\n    all_extensions = df['fileextensions'].apply(flatten_extensions).explode()\n\n    # Get the most common extensions\n    if not all_extensions.empty:\n        plt.figure(figsize=(12, 8))\n        all_extensions_counts = all_extensions.value_counts().head(20) # Top 20\n        sns.barplot(x=all_extensions_counts.values, y=all_extensions_counts.index, palette='viridis')\n        plt.title('Top 20 Most Frequent File Extensions')\n        plt.xlabel('Frequency')\n        plt.ylabel('File Extension')\n        plt.show()\n\n        print(\"\\nTop 20 most frequent file extensions:\")\n        print(all_extensions_counts)\n    else:\n        print(\"No valid file extensions found after processing.\")\nelse:\n    print(\"Data not loaded, skipping file extensions analysis.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Explore Commit Messages**\n\n**Analyzing commit messages directly can be insightful. We can look at message lengths and word counts.**","metadata":{}},{"cell_type":"code","source":"if df is not None:\n    # Calculate message length and word count\n    df['message_length'] = df['commitmessage'].str.len()\n    df['word_count'] = df['commitmessage'].str.split().str.len()\n\n    # Plot distributions\n    plt.figure(figsize=(15, 6))\n\n    plt.subplot(1, 2, 1)\n    sns.histplot(df['message_length'], kde=True, bins=50, color='salmon')\n    plt.title('Distribution of Commit Message Lengths')\n    plt.xlabel('Message Length')\n    plt.ylabel('Frequency')\n\n    plt.subplot(1, 2, 2)\n    sns.histplot(df['word_count'], kde=True, bins=50, color='lightgreen')\n    plt.title('Distribution of Commit Message Word Counts')\n    plt.xlabel('Word Count')\n    plt.ylabel('Frequency')\n\n    plt.tight_layout()\n    plt.show()\n\n    print(\"\\nSummary statistics for Message Length:\")\n    print(df['message_length'].describe())\n\n    print(\"\\nSummary statistics for Word Count:\")\n    print(df['word_count'].describe())\nelse:\n    print(\"Data not loaded, skipping commit message analysis.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Insights and Observations from Exploratory Analysis**\n1. Target Distribution\n\nObservation: The dataset exhibits class imbalance.\n\nMost frequent roles: backend, frontend\n\nLeast frequent role: fullstack\n\nImplications:\n\nUse evaluation metrics robust to imbalance (e.g., Macro F1 score).\n\nConsider techniques like class weighting during model training.\n\n2. Numerical Features\n\nFeatures analyzed: linesadded, linesdeleted, numfileschanged, numcommentsadded\n\nObservation:\n\nlinesadded and linesdeleted distributions are skewed.\n\nnumfileschanged and numcommentsadded have visible spread.\n\nImplications:\n\nSkewed features may benefit from scaling (e.g., RobustScaler).\n\n3. Categorical Feature: Commit Type\n\nObservation:\n\nMost common commit types: bugfix, feature\n\nLess common types are present but infrequent.\n\nProcessing:\n\nOne-hot encoding for traditional models.\n\nExtracted presence of keywords related to commit types.\n\n4. File Extensions\n\nObservation:\n\nCertain file types are more frequently involved in commits.\n\nExtensions were mapped to categories like frontend, backend, etc.\n\nImplications:\n\nCategorical features based on file extensions are informative for role prediction.\n\n5. Commit Messages\n\nObservation:\n\nDistribution of message lengths and word counts indicates typical verbosity.\n\nContent is rich and informative for predicting roles.\n\nProcessing:\n\nExtracted keyword-based features.\n\nFine-tuned LLM for capturing complex text patterns beyond simple features.\n\nImplications:\n\nUsing an LLM is justified, as it can capture nuanced patterns in commit messages.\n\n6. Overall Implications\n\nFeature engineering was validated by analysis.\n\nHandling class imbalance is critical.\n\nCommit messages are key predictors, reinforcing the use of LLM-based approaches.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}